{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Weight_Initialization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Lkc5FJHMu3Un"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.activations import relu, sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KEG2yJuSlxr",
        "outputId": "5703ed4c-cea3-4411-9e20-7562c2f73d5e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 7.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch"
      ],
      "metadata": {
        "id": "hNRnkaWDTBBl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra81Vgfj7Coj",
        "outputId": "79fa21f8-3560-4a96-f617-f723123d980a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(A) Classification Problem"
      ],
      "metadata": {
        "id": "Wd-OeU4lTUp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/DL_Krish_Naik/Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13] #Takes columns from 3 to 12\n",
        "y = dataset.iloc[:, 13] #Take 13th column"
      ],
      "metadata": {
        "id": "H16MHTfDvOn_"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dummy variables\n",
        "geography = pd.get_dummies(X['Geography'], drop_first = True)\n",
        "gender = pd.get_dummies(X['Gender'], drop_first = True)"
      ],
      "metadata": {
        "id": "D3EXpsui7m4_"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.concat([X, geography, gender], axis = 1)"
      ],
      "metadata": {
        "id": "5SLzYQyS7nb4"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(['Geography','Gender'], axis = 1)"
      ],
      "metadata": {
        "id": "sCiXKhET8l1-"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "OrTeHkvo8u8j"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n"
      ],
      "metadata": {
        "id": "XAGzcsW49SRV"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building ANN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "eSUs5XFb-JAV"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "dZ67qSYY-cEy"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units = 10, kernel_initializer= 'he_normal', activation = 'relu', input_dim = 11))\n",
        "classifier.add(Dropout(0.3))\n",
        "classifier.add(Dense(units = 20, kernel_initializer= 'he_normal', activation = 'relu'))\n",
        "classifier.add(Dropout(0.4))\n",
        "classifier.add(Dense(units = 15, kernel_initializer= 'he_normal', activation = 'relu'))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "LU3Hzp-r-gqm"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "v3wkhFvt_NMp"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BwL-hqaLpBi",
        "outputId": "e59fec0a-8c20-40c6-e0c4-196b42c41bb6"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 20)                220       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 15)                315       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 671\n",
            "Trainable params: 671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = classifier.fit(X_train, y_train, validation_split = 0.33, batch_size = 10, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KfMIX-8K3KB",
        "outputId": "c7a23e0c-ea56-4722-ef6b-02203937971a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.5781 - accuracy: 0.7429 - val_loss: 0.4863 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.5120 - accuracy: 0.7925 - val_loss: 0.4769 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7955 - val_loss: 0.4683 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.7985 - val_loss: 0.4584 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.7992 - val_loss: 0.4503 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4549 - accuracy: 0.8000 - val_loss: 0.4451 - val_accuracy: 0.7959\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8033 - val_loss: 0.4424 - val_accuracy: 0.7989\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8041 - val_loss: 0.4406 - val_accuracy: 0.7982\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8024 - val_loss: 0.4388 - val_accuracy: 0.7986\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4422 - accuracy: 0.8056 - val_loss: 0.4378 - val_accuracy: 0.8005\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4375 - accuracy: 0.8089 - val_loss: 0.4332 - val_accuracy: 0.8114\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.4355 - accuracy: 0.8099 - val_loss: 0.4351 - val_accuracy: 0.8031\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8138 - val_loss: 0.4300 - val_accuracy: 0.8092\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8177 - val_loss: 0.4275 - val_accuracy: 0.8054\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.8196 - val_loss: 0.4227 - val_accuracy: 0.8122\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.4179 - accuracy: 0.8222 - val_loss: 0.4140 - val_accuracy: 0.8183\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4165 - accuracy: 0.8293 - val_loss: 0.4108 - val_accuracy: 0.8194\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.4094 - accuracy: 0.8309 - val_loss: 0.4044 - val_accuracy: 0.8292\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8339 - val_loss: 0.4042 - val_accuracy: 0.8220\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8349 - val_loss: 0.3942 - val_accuracy: 0.8326\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8377 - val_loss: 0.3925 - val_accuracy: 0.8326\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3919 - accuracy: 0.8388 - val_loss: 0.3909 - val_accuracy: 0.8281\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.8364 - val_loss: 0.3891 - val_accuracy: 0.8357\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3957 - accuracy: 0.8380 - val_loss: 0.3896 - val_accuracy: 0.8254\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8397 - val_loss: 0.3870 - val_accuracy: 0.8273\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3824 - accuracy: 0.8429 - val_loss: 0.3774 - val_accuracy: 0.8432\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.3878 - accuracy: 0.8421 - val_loss: 0.3795 - val_accuracy: 0.8444\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3891 - accuracy: 0.8431 - val_loss: 0.3776 - val_accuracy: 0.8391\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.8416 - val_loss: 0.3763 - val_accuracy: 0.8391\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3872 - accuracy: 0.8399 - val_loss: 0.3788 - val_accuracy: 0.8323\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8464 - val_loss: 0.3762 - val_accuracy: 0.8413\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3839 - accuracy: 0.8391 - val_loss: 0.3751 - val_accuracy: 0.8432\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8425 - val_loss: 0.3745 - val_accuracy: 0.8402\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8406 - val_loss: 0.3700 - val_accuracy: 0.8436\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3806 - accuracy: 0.8386 - val_loss: 0.3689 - val_accuracy: 0.8432\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8434 - val_loss: 0.3741 - val_accuracy: 0.8440\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.8367 - val_loss: 0.3711 - val_accuracy: 0.8425\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8489 - val_loss: 0.3702 - val_accuracy: 0.8478\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3830 - accuracy: 0.8406 - val_loss: 0.3703 - val_accuracy: 0.8436\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8390 - val_loss: 0.3719 - val_accuracy: 0.8406\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8474 - val_loss: 0.3665 - val_accuracy: 0.8463\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8408 - val_loss: 0.3661 - val_accuracy: 0.8463\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3683 - accuracy: 0.8455 - val_loss: 0.3628 - val_accuracy: 0.8489\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8446 - val_loss: 0.3646 - val_accuracy: 0.8489\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8496 - val_loss: 0.3634 - val_accuracy: 0.8482\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.8503 - val_loss: 0.3632 - val_accuracy: 0.8489\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3704 - accuracy: 0.8490 - val_loss: 0.3621 - val_accuracy: 0.8538\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8427 - val_loss: 0.3618 - val_accuracy: 0.8482\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8505 - val_loss: 0.3653 - val_accuracy: 0.8493\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.3702 - accuracy: 0.8425 - val_loss: 0.3670 - val_accuracy: 0.8455\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8475 - val_loss: 0.3632 - val_accuracy: 0.8489\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3766 - accuracy: 0.8442 - val_loss: 0.3660 - val_accuracy: 0.8455\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3760 - accuracy: 0.8461 - val_loss: 0.3677 - val_accuracy: 0.8429\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.8449 - val_loss: 0.3630 - val_accuracy: 0.8493\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8531 - val_loss: 0.3674 - val_accuracy: 0.8421\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3729 - accuracy: 0.8436 - val_loss: 0.3645 - val_accuracy: 0.8455\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8442 - val_loss: 0.3673 - val_accuracy: 0.8436\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8451 - val_loss: 0.3696 - val_accuracy: 0.8470\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3710 - accuracy: 0.8462 - val_loss: 0.3667 - val_accuracy: 0.8482\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3767 - accuracy: 0.8395 - val_loss: 0.3702 - val_accuracy: 0.8448\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8466 - val_loss: 0.3627 - val_accuracy: 0.8493\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8421 - val_loss: 0.3628 - val_accuracy: 0.8485\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8440 - val_loss: 0.3648 - val_accuracy: 0.8489\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8481 - val_loss: 0.3658 - val_accuracy: 0.8440\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8475 - val_loss: 0.3617 - val_accuracy: 0.8504\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3707 - accuracy: 0.8462 - val_loss: 0.3648 - val_accuracy: 0.8478\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8464 - val_loss: 0.3648 - val_accuracy: 0.8497\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8487 - val_loss: 0.3608 - val_accuracy: 0.8501\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8466 - val_loss: 0.3604 - val_accuracy: 0.8523\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8517 - val_loss: 0.3601 - val_accuracy: 0.8512\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8444 - val_loss: 0.3618 - val_accuracy: 0.8459\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8498 - val_loss: 0.3579 - val_accuracy: 0.8516\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3683 - accuracy: 0.8440 - val_loss: 0.3602 - val_accuracy: 0.8527\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8436 - val_loss: 0.3648 - val_accuracy: 0.8455\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3589 - accuracy: 0.8492 - val_loss: 0.3603 - val_accuracy: 0.8497\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3645 - accuracy: 0.8457 - val_loss: 0.3597 - val_accuracy: 0.8489\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8498 - val_loss: 0.3612 - val_accuracy: 0.8474\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8539 - val_loss: 0.3589 - val_accuracy: 0.8482\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8526 - val_loss: 0.3601 - val_accuracy: 0.8527\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8472 - val_loss: 0.3627 - val_accuracy: 0.8489\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3663 - accuracy: 0.8455 - val_loss: 0.3580 - val_accuracy: 0.8497\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8489 - val_loss: 0.3606 - val_accuracy: 0.8493\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8451 - val_loss: 0.3584 - val_accuracy: 0.8493\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8494 - val_loss: 0.3599 - val_accuracy: 0.8463\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8449 - val_loss: 0.3605 - val_accuracy: 0.8459\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3631 - accuracy: 0.8489 - val_loss: 0.3618 - val_accuracy: 0.8482\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3664 - accuracy: 0.8457 - val_loss: 0.3620 - val_accuracy: 0.8466\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8483 - val_loss: 0.3632 - val_accuracy: 0.8531\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8457 - val_loss: 0.3596 - val_accuracy: 0.8504\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 2s 3ms/step - loss: 0.3578 - accuracy: 0.8475 - val_loss: 0.3595 - val_accuracy: 0.8485\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8461 - val_loss: 0.3581 - val_accuracy: 0.8478\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8485 - val_loss: 0.3589 - val_accuracy: 0.8523\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8485 - val_loss: 0.3586 - val_accuracy: 0.8535\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8466 - val_loss: 0.3600 - val_accuracy: 0.8508\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3610 - accuracy: 0.8474 - val_loss: 0.3563 - val_accuracy: 0.8535\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8509 - val_loss: 0.3598 - val_accuracy: 0.8497\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3567 - accuracy: 0.8494 - val_loss: 0.3603 - val_accuracy: 0.8512\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3578 - accuracy: 0.8541 - val_loss: 0.3569 - val_accuracy: 0.8519\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8483 - val_loss: 0.3581 - val_accuracy: 0.8504\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8474 - val_loss: 0.3586 - val_accuracy: 0.8523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwgCef_nLUFV",
        "outputId": "b5de2948-a866-4c36-8446-c30c3553ad82"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "rW840wEhMSrn"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "id": "JUg74SUrMbNe"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNbNntgGMx7a",
        "outputId": "2d466e3b-6820-4da6-890b-d908aa576233"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8675"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R55J3IwJMzXD",
        "outputId": "cacc2ed0-af46-4e04-8854-1eb6381f261c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1561,   34],\n",
              "       [ 231,  174]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform Hyperparameter Optimization\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization"
      ],
      "metadata": {
        "id": "_rsimxfffm8J"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(layers, activation):\n",
        "    model = Sequential()\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i==0:\n",
        "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "        else:\n",
        "            model.add(Dense(nodes))\n",
        "            model.add(Activation(activation))\n",
        "            model.add(Dropout(0.3))\n",
        "            \n",
        "    model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid')) # Note: no activation beyond this point\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "  "
      ],
      "metadata": {
        "id": "kKhj5xtwgRG_"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCz0o7eqheP-",
        "outputId": "924092c1-e8df-41bf-820c-956ed0f39efd"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [[20], [40, 20], [45, 30, 15]]\n",
        "activations = ['sigmoid', 'relu']\n",
        "param_grid = dict(layers=layers, activation=activations, batch_size = [128, 256], epochs=[30])\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)"
      ],
      "metadata": {
        "id": "ZjFgKZyBhgMN"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "PLZYaexYhjzq"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result.best_score_, grid_result.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZkA6w9jZVV",
        "outputId": "51f92a72-adea-42ae-8634-dad5f48a2e34"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8557499885559082,\n",
              " {'activation': 'relu', 'batch_size': 128, 'epochs': 30, 'layers': [40, 20]})"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = grid.predict(X_test)\n",
        "y_pred = (pred_y > 0.5)\n",
        "[i for i , x in enumerate(y_pred) if x]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1khBd7hjpRj",
        "outputId": "6e18cd5b-4da4-4a30-f55d-3b7e44763d92"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5,\n",
              " 9,\n",
              " 20,\n",
              " 44,\n",
              " 50,\n",
              " 65,\n",
              " 69,\n",
              " 70,\n",
              " 73,\n",
              " 74,\n",
              " 76,\n",
              " 80,\n",
              " 84,\n",
              " 88,\n",
              " 93,\n",
              " 122,\n",
              " 128,\n",
              " 137,\n",
              " 147,\n",
              " 149,\n",
              " 154,\n",
              " 155,\n",
              " 182,\n",
              " 197,\n",
              " 203,\n",
              " 207,\n",
              " 212,\n",
              " 213,\n",
              " 229,\n",
              " 251,\n",
              " 253,\n",
              " 273,\n",
              " 279,\n",
              " 303,\n",
              " 308,\n",
              " 318,\n",
              " 320,\n",
              " 323,\n",
              " 341,\n",
              " 343,\n",
              " 353,\n",
              " 355,\n",
              " 365,\n",
              " 367,\n",
              " 377,\n",
              " 386,\n",
              " 388,\n",
              " 405,\n",
              " 418,\n",
              " 432,\n",
              " 434,\n",
              " 452,\n",
              " 454,\n",
              " 465,\n",
              " 467,\n",
              " 473,\n",
              " 481,\n",
              " 485,\n",
              " 490,\n",
              " 491,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 513,\n",
              " 560,\n",
              " 563,\n",
              " 573,\n",
              " 576,\n",
              " 579,\n",
              " 585,\n",
              " 591,\n",
              " 602,\n",
              " 609,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 631,\n",
              " 639,\n",
              " 654,\n",
              " 672,\n",
              " 681,\n",
              " 685,\n",
              " 733,\n",
              " 736,\n",
              " 758,\n",
              " 773,\n",
              " 787,\n",
              " 795,\n",
              " 804,\n",
              " 821,\n",
              " 827,\n",
              " 836,\n",
              " 856,\n",
              " 860,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 894,\n",
              " 900,\n",
              " 923,\n",
              " 927,\n",
              " 940,\n",
              " 941,\n",
              " 950,\n",
              " 957,\n",
              " 978,\n",
              " 1004,\n",
              " 1009,\n",
              " 1023,\n",
              " 1025,\n",
              " 1035,\n",
              " 1048,\n",
              " 1062,\n",
              " 1070,\n",
              " 1089,\n",
              " 1095,\n",
              " 1101,\n",
              " 1104,\n",
              " 1105,\n",
              " 1110,\n",
              " 1117,\n",
              " 1123,\n",
              " 1126,\n",
              " 1128,\n",
              " 1131,\n",
              " 1137,\n",
              " 1138,\n",
              " 1139,\n",
              " 1148,\n",
              " 1159,\n",
              " 1174,\n",
              " 1180,\n",
              " 1194,\n",
              " 1198,\n",
              " 1218,\n",
              " 1248,\n",
              " 1257,\n",
              " 1268,\n",
              " 1275,\n",
              " 1280,\n",
              " 1281,\n",
              " 1284,\n",
              " 1295,\n",
              " 1306,\n",
              " 1316,\n",
              " 1335,\n",
              " 1348,\n",
              " 1357,\n",
              " 1388,\n",
              " 1390,\n",
              " 1402,\n",
              " 1430,\n",
              " 1436,\n",
              " 1444,\n",
              " 1446,\n",
              " 1452,\n",
              " 1465,\n",
              " 1468,\n",
              " 1469,\n",
              " 1472,\n",
              " 1497,\n",
              " 1500,\n",
              " 1517,\n",
              " 1529,\n",
              " 1532,\n",
              " 1538,\n",
              " 1539,\n",
              " 1558,\n",
              " 1568,\n",
              " 1570,\n",
              " 1579,\n",
              " 1581,\n",
              " 1584,\n",
              " 1585,\n",
              " 1592,\n",
              " 1614,\n",
              " 1619,\n",
              " 1649,\n",
              " 1666,\n",
              " 1681,\n",
              " 1693,\n",
              " 1695,\n",
              " 1705,\n",
              " 1715,\n",
              " 1718,\n",
              " 1726,\n",
              " 1736,\n",
              " 1742,\n",
              " 1773,\n",
              " 1779,\n",
              " 1788,\n",
              " 1789,\n",
              " 1806,\n",
              " 1808,\n",
              " 1825,\n",
              " 1857,\n",
              " 1870,\n",
              " 1873,\n",
              " 1877,\n",
              " 1889,\n",
              " 1901,\n",
              " 1908,\n",
              " 1920,\n",
              " 1933,\n",
              " 1944,\n",
              " 1956,\n",
              " 1966,\n",
              " 1981]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "score = accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "id": "jWu41D3Ej7OQ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paWfSAK7j-6c",
        "outputId": "df9a7529-2a17-4763-d3a5-46583ca56573"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1560,   35],\n",
              "       [ 231,  174]])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DekYsKzij_pz",
        "outputId": "b97288d0-3987-43f0-99cf-d0fa3e874601"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(B) Regression Problem"
      ],
      "metadata": {
        "id": "NO8LQkKbTYjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DL_Krish_Naik/Real_Combine.csv')"
      ],
      "metadata": {
        "id": "i1V-ap-ITYK8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BAz7_l1lUffX",
        "outputId": "72e68b9d-2974-4f6a-e1e3-66c4a8e53719"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         T    TM    Tm     SLP     H   VV     V    VM      PM 2.5\n",
              "0      7.4   9.8   4.8  1017.6  93.0  0.5   4.3   9.4  219.720833\n",
              "1      7.8  12.7   4.4  1018.5  87.0  0.6   4.4  11.1  182.187500\n",
              "2      6.7  13.4   2.4  1019.4  82.0  0.6   4.8  11.1  154.037500\n",
              "3      8.6  15.5   3.3  1018.7  72.0  0.8   8.1  20.6  223.208333\n",
              "4     12.4  20.9   4.4  1017.3  61.0  1.3   8.7  22.2  200.645833\n",
              "...    ...   ...   ...     ...   ...  ...   ...   ...         ...\n",
              "1088  18.1  24.0  11.2  1015.4  56.0  1.8  15.9  25.9  288.416667\n",
              "1089  17.8  25.0  10.7  1015.8  54.0  2.3   9.4  22.2  256.833333\n",
              "1090  13.9  24.5  11.4  1015.0  95.0  0.6   8.7  14.8  169.000000\n",
              "1091  16.3  23.0   9.8  1016.9  78.0  1.1   7.4  16.5  186.041667\n",
              "1092  16.3  23.4   9.0  1017.3  68.0  1.3   7.8  18.3  185.583333\n",
              "\n",
              "[1093 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2f6ac6a-2aa6-4954-bbc5-a630edf3ef5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TM</th>\n",
              "      <th>Tm</th>\n",
              "      <th>SLP</th>\n",
              "      <th>H</th>\n",
              "      <th>VV</th>\n",
              "      <th>V</th>\n",
              "      <th>VM</th>\n",
              "      <th>PM 2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>219.720833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>182.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>154.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.6</td>\n",
              "      <td>15.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1018.7</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>20.6</td>\n",
              "      <td>223.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>200.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>18.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>15.9</td>\n",
              "      <td>25.9</td>\n",
              "      <td>288.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1089</th>\n",
              "      <td>17.8</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>1015.8</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>22.2</td>\n",
              "      <td>256.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090</th>\n",
              "      <td>13.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>11.4</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>8.7</td>\n",
              "      <td>14.8</td>\n",
              "      <td>169.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>16.5</td>\n",
              "      <td>186.041667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>18.3</td>\n",
              "      <td>185.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1093 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2f6ac6a-2aa6-4954-bbc5-a630edf3ef5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2f6ac6a-2aa6-4954-bbc5-a630edf3ef5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2f6ac6a-2aa6-4954-bbc5-a630edf3ef5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=[\"PM 2.5\"], inplace = True)"
      ],
      "metadata": {
        "id": "e9lIwjQRcGC_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zqquME8HcT-p",
        "outputId": "dc7add4d-cb38-4e30-f542-63cbcb050c3c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         T    TM    Tm     SLP     H   VV     V    VM      PM 2.5\n",
              "0      7.4   9.8   4.8  1017.6  93.0  0.5   4.3   9.4  219.720833\n",
              "1      7.8  12.7   4.4  1018.5  87.0  0.6   4.4  11.1  182.187500\n",
              "2      6.7  13.4   2.4  1019.4  82.0  0.6   4.8  11.1  154.037500\n",
              "3      8.6  15.5   3.3  1018.7  72.0  0.8   8.1  20.6  223.208333\n",
              "4     12.4  20.9   4.4  1017.3  61.0  1.3   8.7  22.2  200.645833\n",
              "...    ...   ...   ...     ...   ...  ...   ...   ...         ...\n",
              "1088  18.1  24.0  11.2  1015.4  56.0  1.8  15.9  25.9  288.416667\n",
              "1089  17.8  25.0  10.7  1015.8  54.0  2.3   9.4  22.2  256.833333\n",
              "1090  13.9  24.5  11.4  1015.0  95.0  0.6   8.7  14.8  169.000000\n",
              "1091  16.3  23.0   9.8  1016.9  78.0  1.1   7.4  16.5  186.041667\n",
              "1092  16.3  23.4   9.0  1017.3  68.0  1.3   7.8  18.3  185.583333\n",
              "\n",
              "[1092 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-623ad546-c5f6-4e26-b2b1-a0c8fda290c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TM</th>\n",
              "      <th>Tm</th>\n",
              "      <th>SLP</th>\n",
              "      <th>H</th>\n",
              "      <th>VV</th>\n",
              "      <th>V</th>\n",
              "      <th>VM</th>\n",
              "      <th>PM 2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>219.720833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>182.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>154.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.6</td>\n",
              "      <td>15.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1018.7</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>20.6</td>\n",
              "      <td>223.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>200.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>18.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>15.9</td>\n",
              "      <td>25.9</td>\n",
              "      <td>288.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1089</th>\n",
              "      <td>17.8</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>1015.8</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>22.2</td>\n",
              "      <td>256.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090</th>\n",
              "      <td>13.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>11.4</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>8.7</td>\n",
              "      <td>14.8</td>\n",
              "      <td>169.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>16.5</td>\n",
              "      <td>186.041667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>18.3</td>\n",
              "      <td>185.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1092 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623ad546-c5f6-4e26-b2b1-a0c8fda290c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-623ad546-c5f6-4e26-b2b1-a0c8fda290c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-623ad546-c5f6-4e26-b2b1-a0c8fda290c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,-1]\n",
        "y = df.iloc[:-1]"
      ],
      "metadata": {
        "id": "_Me67CE8Ug0e"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk1WwgQsaZps",
        "outputId": "574129d4-1686-4972-de09-46936b46d609"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       219.720833\n",
              "1       182.187500\n",
              "2       154.037500\n",
              "3       223.208333\n",
              "4       200.645833\n",
              "           ...    \n",
              "1087    284.166667\n",
              "1088    288.416667\n",
              "1089    256.833333\n",
              "1090    169.000000\n",
              "1091    186.041667\n",
              "Name: PM 2.5, Length: 1091, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_HJ-MImyYfU4",
        "outputId": "65940632-e54a-4645-b3ec-74e0458a822c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         T    TM    Tm     SLP     H   VV     V    VM      PM 2.5\n",
              "0      7.4   9.8   4.8  1017.6  93.0  0.5   4.3   9.4  219.720833\n",
              "1      7.8  12.7   4.4  1018.5  87.0  0.6   4.4  11.1  182.187500\n",
              "2      6.7  13.4   2.4  1019.4  82.0  0.6   4.8  11.1  154.037500\n",
              "3      8.6  15.5   3.3  1018.7  72.0  0.8   8.1  20.6  223.208333\n",
              "4     12.4  20.9   4.4  1017.3  61.0  1.3   8.7  22.2  200.645833\n",
              "...    ...   ...   ...     ...   ...  ...   ...   ...         ...\n",
              "1087  16.3  23.0   6.6  1016.9  61.0  1.0   9.4  20.6  284.166667\n",
              "1088  18.1  24.0  11.2  1015.4  56.0  1.8  15.9  25.9  288.416667\n",
              "1089  17.8  25.0  10.7  1015.8  54.0  2.3   9.4  22.2  256.833333\n",
              "1090  13.9  24.5  11.4  1015.0  95.0  0.6   8.7  14.8  169.000000\n",
              "1091  16.3  23.0   9.8  1016.9  78.0  1.1   7.4  16.5  186.041667\n",
              "\n",
              "[1091 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96b9d55f-b2b6-46a2-850d-d93f3905b494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TM</th>\n",
              "      <th>Tm</th>\n",
              "      <th>SLP</th>\n",
              "      <th>H</th>\n",
              "      <th>VV</th>\n",
              "      <th>V</th>\n",
              "      <th>VM</th>\n",
              "      <th>PM 2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>219.720833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>182.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>154.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.6</td>\n",
              "      <td>15.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1018.7</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>20.6</td>\n",
              "      <td>223.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>200.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1087</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>20.6</td>\n",
              "      <td>284.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>18.1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>15.9</td>\n",
              "      <td>25.9</td>\n",
              "      <td>288.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1089</th>\n",
              "      <td>17.8</td>\n",
              "      <td>25.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>1015.8</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>22.2</td>\n",
              "      <td>256.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090</th>\n",
              "      <td>13.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>11.4</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>8.7</td>\n",
              "      <td>14.8</td>\n",
              "      <td>169.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>16.3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>16.5</td>\n",
              "      <td>186.041667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1091 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96b9d55f-b2b6-46a2-850d-d93f3905b494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96b9d55f-b2b6-46a2-850d-d93f3905b494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96b9d55f-b2b6-46a2-850d-d93f3905b494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='mean_absolute_error',\n",
        "        metrics=['mean_absolute_error'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "qGmuQFR_UmNF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_mean_absolute_error',\n",
        "    max_trials=5,\n",
        "    executions_per_trial = 3,\n",
        "    directory = 'proj',\n",
        "    project_name = 'Air Quality Index'\n",
        ")"
      ],
      "metadata": {
        "id": "vaq1biRvW1dE"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUr7zSWZXsR9",
        "outputId": "c4cd2c1f-1800-40fb-baca-ec6ff6f2d4c5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0)"
      ],
      "metadata": {
        "id": "BuhBlHO4X0ny"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVbLVTFYCKH",
        "outputId": "c9e3d51a-a7d2-4cb3-ab1b-336f3ffc9946"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 19s]\n",
            "val_mean_absolute_error: 135.95547993977866\n",
            "\n",
            "Best val_mean_absolute_error So Far: 130.6375528971354\n",
            "Total elapsed time: 00h 01m 08s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IM_h_c0cmlo",
        "outputId": "34d6b47a-30ad-4382-9a5c-e24fddf0233a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in proj/Air Quality Index\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f34bf09e8d0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 12\n",
            "units_0: 288\n",
            "units_1: 512\n",
            "learning_rate: 0.01\n",
            "units_2: 448\n",
            "units_3: 320\n",
            "units_4: 256\n",
            "units_5: 192\n",
            "units_6: 288\n",
            "units_7: 32\n",
            "units_8: 32\n",
            "units_9: 32\n",
            "units_10: 32\n",
            "units_11: 32\n",
            "Score: 130.6375528971354\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 17\n",
            "units_0: 224\n",
            "units_1: 480\n",
            "learning_rate: 0.001\n",
            "units_2: 224\n",
            "units_3: 416\n",
            "units_4: 448\n",
            "units_5: 512\n",
            "units_6: 480\n",
            "units_7: 64\n",
            "units_8: 448\n",
            "units_9: 160\n",
            "units_10: 64\n",
            "units_11: 480\n",
            "units_12: 32\n",
            "units_13: 32\n",
            "units_14: 32\n",
            "units_15: 32\n",
            "units_16: 32\n",
            "Score: 133.25576782226562\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 18\n",
            "units_0: 96\n",
            "units_1: 480\n",
            "learning_rate: 0.0001\n",
            "units_2: 384\n",
            "units_3: 448\n",
            "units_4: 96\n",
            "units_5: 288\n",
            "units_6: 256\n",
            "units_7: 320\n",
            "units_8: 96\n",
            "units_9: 416\n",
            "units_10: 160\n",
            "units_11: 480\n",
            "units_12: 448\n",
            "units_13: 192\n",
            "units_14: 192\n",
            "units_15: 160\n",
            "units_16: 320\n",
            "units_17: 32\n",
            "Score: 135.95547993977866\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 14\n",
            "units_0: 352\n",
            "units_1: 192\n",
            "learning_rate: 0.0001\n",
            "units_2: 160\n",
            "units_3: 128\n",
            "units_4: 352\n",
            "units_5: 160\n",
            "units_6: 320\n",
            "units_7: 224\n",
            "units_8: 32\n",
            "units_9: 320\n",
            "units_10: 128\n",
            "units_11: 224\n",
            "units_12: 128\n",
            "units_13: 448\n",
            "units_14: 192\n",
            "units_15: 384\n",
            "units_16: 288\n",
            "Score: 135.97607421875\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 7\n",
            "units_0: 288\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 32\n",
            "units_3: 32\n",
            "units_4: 32\n",
            "units_5: 32\n",
            "units_6: 32\n",
            "Score: 136.49832661946616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R1SIKwjxc7Qb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}